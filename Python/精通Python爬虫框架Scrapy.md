![](https://img3.doubanio.com/view/subject/l/public/s29705995.jpg)



# 第1章 Scrapy简介	

​	1.1 初识Scrapy	
​	1.2 喜欢Scrapy的更多理由	
​	1.3 关于本书：目标和用途	
​	1.4 掌握自动化数据爬取的重要性	
​	1.5 在充满爬虫的世界里做一个好公民	
​	1.6 Scrapy不是什么	
​	1.7 本章小结	

# 第2章 理解HTML和XPath	

​	2.1 HTML、DOM树表示以及XPath	
​	2.2 使用XPath选择HTML元素	
​	2.3 本章小结	

# 第3章 爬虫基础	

​	3.1 安装Scrapy 	
​	3.2 UR2IM——基本抓取流程 	
​	3.3 一个Scrapy项目 	
​	3.4 抽取更多的URL 	
​	3.5 本章小结 	

# 第4章 从Scrapy到移动应用	

​	4.1 选择手机应用框架	
​	4.2 创建数据库和集合	
​	4.3 使用Scrapy填充数据库	
​	4.4 创建手机应用	
​	4.5 本章小结	

# 第5章 迅速的爬虫技巧	

​	5.1 需要登录的爬虫	
​	5.2 使用JSON API和AJAX页面的爬虫	
​	5.3 30倍速的房产爬虫	
​	5.4 基于Excel文件爬取的爬虫	
​	5.5 本章小结	

# 第6章 部署到Scrapinghub	

​	6.1 注册、登录及创建项目	
​	6.2 部署爬虫与计划运行	
​	6.3 访问item	
​	6.4 计划定时爬取	
​	6.5 本章小结	

# 第7章 配置与管理	

​	7.1 使用Scrapy设置	
​	7.2 基本设置 	
​	7.3 进阶设置 	
​	7.4 本章小结 	

# 第8章 Scrapy编程	

​	8.1 Scrapy是一个Twisted应用 	
​	8.2 Scrapy架构概述 	
​	8.3 示例 1：非常简单的管道 	
​	8.4 信号 	
​	8.5 示例 2：测量吞吐量和延时的扩展 	
​	8.6 中间件延伸 	
​	8.7 本章小结 	

# 第9章 管道秘诀	

​	9.1 使用REST API	
​	9.2 与标准Python客户端建立数据库接口	
​	9.3 使用Twisted专用客户端建立服务接口	
​	9.4 为CPU密集型、阻塞或遗留功能建立接口	
​	9.5 本章小结	

# 第10章 理解Scrapy性能	

​	10.1 Scrapy引擎——一种直观方式 	
​	10.2 使用telnet获得组件利用率 	
​	10.3 基准系统 	
​	10.4 标准性能模型 	
​	10.5 解决性能问题 	
​	10.6 故障排除流程 	
​	10.7 本章小结 	

# 第11章 使用Scrapyd与实时分析进行分布式爬取

​	11.1 房产的标题是如何影响价格的 	
​	11.2 Scrapyd 	
​	11.3 分布式系统概述 	
​	11.4 爬虫和中间件的变化 	
​	11.5 创建自定义监控命令 	
​	11.6 使用Apache Spark流计算偏移量 	
​	11.7 运行分布式爬取 	
​	11.8 系统性能 	
​	11.9 关键要点 	
​	11.10 本章小结 	
附录A 必备软件的安装与故障排除	